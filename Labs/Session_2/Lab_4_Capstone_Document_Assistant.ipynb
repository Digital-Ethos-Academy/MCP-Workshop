{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Capstone - Document Assistant MCP Server\n",
    "\n",
    "**Objective:** Build a complete MCP server that serves as a Document Assistant, combining tools, resources, and prompts.\n",
    "\n",
    "**Duration:** ~45 minutes\n",
    "\n",
    "**What You'll Build:**\n",
    "- A fully-featured MCP server for document management\n",
    "- Search tools to find documents by content or metadata\n",
    "- Resources to expose document contents\n",
    "- Prompts for common document analysis tasks\n",
    "\n",
    "**Prerequisites:**\n",
    "- Completed Labs 1-3\n",
    "- Understanding of MCP tools, resources, and prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Project Overview\n",
    "\n",
    "The Document Assistant will help users:\n",
    "1. **Search** documents by keyword or metadata\n",
    "2. **Read** document contents via resources\n",
    "3. **Analyze** documents using pre-built prompts\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "Document Assistant MCP Server\n",
    "├── Tools\n",
    "│   ├── search_documents(query) - Search by content\n",
    "│   ├── list_documents() - List all documents\n",
    "│   └── get_document_stats() - Get statistics\n",
    "├── Resources\n",
    "│   ├── doc://{doc_id} - Individual document content\n",
    "│   └── docs://catalog - Full document catalog\n",
    "└── Prompts\n",
    "    ├── summarize - Summarize a document\n",
    "    ├── compare - Compare two documents\n",
    "    └── extract-insights - Extract key insights\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Setting Up the Project\n",
    "\n",
    "Let's create the project structure and sample documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create project directory\n",
    "os.makedirs(\"document_assistant\", exist_ok=True)\n",
    "os.makedirs(\"document_assistant/documents\", exist_ok=True)\n",
    "\n",
    "print(\"Project structure created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample documents for testing\n",
    "\n",
    "documents = {\n",
    "    \"project_proposal.md\": '''# Project Proposal: AI Integration\n",
    "\n",
    "## Executive Summary\n",
    "This proposal outlines a plan to integrate AI capabilities into our existing product suite.\n",
    "\n",
    "## Objectives\n",
    "1. Improve customer experience through intelligent recommendations\n",
    "2. Automate repetitive tasks to increase efficiency\n",
    "3. Provide predictive analytics for business decisions\n",
    "\n",
    "## Timeline\n",
    "- Phase 1: Research and Planning (Q1)\n",
    "- Phase 2: Development (Q2-Q3)\n",
    "- Phase 3: Testing and Deployment (Q4)\n",
    "\n",
    "## Budget\n",
    "Estimated total: $500,000\n",
    "''',\n",
    "    \n",
    "    \"technical_spec.md\": '''# Technical Specification: API Gateway\n",
    "\n",
    "## Overview\n",
    "The API Gateway will serve as the central entry point for all microservices.\n",
    "\n",
    "## Requirements\n",
    "- Handle 10,000 requests per second\n",
    "- Support OAuth 2.0 authentication\n",
    "- Implement rate limiting\n",
    "- Provide request/response logging\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "Client -> Load Balancer -> API Gateway -> Microservices\n",
    "```\n",
    "\n",
    "## Technologies\n",
    "- Language: Go\n",
    "- Framework: Gin\n",
    "- Database: PostgreSQL\n",
    "- Cache: Redis\n",
    "''',\n",
    "    \n",
    "    \"meeting_notes.md\": '''# Meeting Notes: Q4 Planning\n",
    "\n",
    "**Date:** October 15, 2024\n",
    "**Attendees:** Alice, Bob, Carol, David\n",
    "\n",
    "## Discussion Points\n",
    "\n",
    "### Budget Review\n",
    "- Current spending is 5% under budget\n",
    "- Proposal to reallocate funds to AI initiative\n",
    "\n",
    "### Hiring Plans\n",
    "- Need 3 senior engineers\n",
    "- 1 product manager opening\n",
    "\n",
    "### Action Items\n",
    "- [ ] Alice: Finalize budget proposal\n",
    "- [ ] Bob: Post job listings\n",
    "- [ ] Carol: Schedule follow-up meeting\n",
    "\n",
    "## Next Meeting\n",
    "October 22, 2024 at 2:00 PM\n",
    "''',\n",
    "    \n",
    "    \"security_policy.md\": '''# Security Policy\n",
    "\n",
    "## Purpose\n",
    "This document outlines security requirements for all company systems.\n",
    "\n",
    "## Password Requirements\n",
    "- Minimum 12 characters\n",
    "- Must include uppercase, lowercase, numbers, and symbols\n",
    "- Changed every 90 days\n",
    "\n",
    "## Data Classification\n",
    "1. **Public**: Marketing materials, public documentation\n",
    "2. **Internal**: Employee communications, internal processes\n",
    "3. **Confidential**: Customer data, financial records\n",
    "4. **Restricted**: Security credentials, encryption keys\n",
    "\n",
    "## Incident Response\n",
    "1. Identify and contain the threat\n",
    "2. Notify security team immediately\n",
    "3. Document all actions taken\n",
    "4. Conduct post-incident review\n",
    "'''\n",
    "}\n",
    "\n",
    "# Save documents\n",
    "for filename, content in documents.items():\n",
    "    filepath = f\"document_assistant/documents/{filename}\"\n",
    "    with open(filepath, \"w\") as f:\n",
    "        f.write(content)\n",
    "    print(f\"Created: {filepath}\")\n",
    "\n",
    "print(f\"\\nCreated {len(documents)} sample documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Building the Server - Step by Step\n",
    "\n",
    "Let's build the Document Assistant incrementally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Basic Server Structure\n",
    "\n",
    "First, create the server with document loading capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1_code = '''\n",
    "\"\"\"Document Assistant MCP Server - Step 1: Basic Structure\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "# Configuration\n",
    "DOCUMENTS_DIR = Path(__file__).parent / \"documents\"\n",
    "\n",
    "# Create the MCP server\n",
    "mcp = FastMCP(\n",
    "    \"Document Assistant\",\n",
    "    description=\"An MCP server for document management and analysis\"\n",
    ")\n",
    "\n",
    "# Document storage (loaded at startup)\n",
    "document_cache = {}\n",
    "\n",
    "def load_documents():\n",
    "    \"\"\"Load all documents from the documents directory.\"\"\"\n",
    "    global document_cache\n",
    "    document_cache = {}\n",
    "    \n",
    "    if not DOCUMENTS_DIR.exists():\n",
    "        return\n",
    "    \n",
    "    for filepath in DOCUMENTS_DIR.glob(\"*.md\"):\n",
    "        doc_id = filepath.stem  # filename without extension\n",
    "        stat = filepath.stat()\n",
    "        \n",
    "        document_cache[doc_id] = {\n",
    "            \"id\": doc_id,\n",
    "            \"filename\": filepath.name,\n",
    "            \"path\": str(filepath),\n",
    "            \"content\": filepath.read_text(),\n",
    "            \"size\": stat.st_size,\n",
    "            \"modified\": datetime.fromtimestamp(stat.st_mtime).isoformat()\n",
    "        }\n",
    "    \n",
    "    print(f\"Loaded {len(document_cache)} documents\")\n",
    "\n",
    "# Load documents at startup\n",
    "load_documents()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run()\n",
    "'''\n",
    "\n",
    "with open(\"document_assistant/server_step1.py\", \"w\") as f:\n",
    "    f.write(step1_code)\n",
    "\n",
    "print(\"Step 1 complete: Basic server structure created\")\n",
    "print(\"\\nThis creates:\")\n",
    "print(\"- MCP server instance\")\n",
    "print(\"- Document loading function\")\n",
    "print(\"- Document cache for fast access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Add Search Tools\n",
    "\n",
    "Add tools for searching and listing documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2_code = '''\n",
    "\"\"\"Document Assistant MCP Server - Step 2: Search Tools\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "# Configuration\n",
    "DOCUMENTS_DIR = Path(__file__).parent / \"documents\"\n",
    "\n",
    "# Create the MCP server\n",
    "mcp = FastMCP(\n",
    "    \"Document Assistant\",\n",
    "    description=\"An MCP server for document management and analysis\"\n",
    ")\n",
    "\n",
    "# Document storage\n",
    "document_cache = {}\n",
    "\n",
    "def load_documents():\n",
    "    \"\"\"Load all documents from the documents directory.\"\"\"\n",
    "    global document_cache\n",
    "    document_cache = {}\n",
    "    \n",
    "    if not DOCUMENTS_DIR.exists():\n",
    "        return\n",
    "    \n",
    "    for filepath in DOCUMENTS_DIR.glob(\"*.md\"):\n",
    "        doc_id = filepath.stem\n",
    "        stat = filepath.stat()\n",
    "        \n",
    "        document_cache[doc_id] = {\n",
    "            \"id\": doc_id,\n",
    "            \"filename\": filepath.name,\n",
    "            \"path\": str(filepath),\n",
    "            \"content\": filepath.read_text(),\n",
    "            \"size\": stat.st_size,\n",
    "            \"modified\": datetime.fromtimestamp(stat.st_mtime).isoformat()\n",
    "        }\n",
    "\n",
    "load_documents()\n",
    "\n",
    "# ============ TOOLS ============\n",
    "\n",
    "@mcp.tool()\n",
    "def list_documents() -> str:\n",
    "    \"\"\"List all available documents with their metadata.\n",
    "    \n",
    "    Returns:\n",
    "        A formatted list of all documents with ID, filename, size, and modification date.\n",
    "    \"\"\"\n",
    "    if not document_cache:\n",
    "        return \"No documents found.\"\n",
    "    \n",
    "    lines = [\"Available Documents:\", \"=\" * 50]\n",
    "    \n",
    "    for doc_id, doc in sorted(document_cache.items()):\n",
    "        lines.append(f\"\\nID: {doc_id}\")\n",
    "        lines.append(f\"  Filename: {doc['filename']}\")\n",
    "        lines.append(f\"  Size: {doc['size']} bytes\")\n",
    "        lines.append(f\"  Modified: {doc['modified']}\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def search_documents(query: str, case_sensitive: bool = False) -> str:\n",
    "    \"\"\"Search for documents containing the specified text.\n",
    "    \n",
    "    Args:\n",
    "        query: The text to search for in document contents\n",
    "        case_sensitive: Whether the search should be case-sensitive (default: False)\n",
    "    \n",
    "    Returns:\n",
    "        A list of matching documents with excerpts showing where the query was found.\n",
    "    \"\"\"\n",
    "    if not query.strip():\n",
    "        return \"Error: Please provide a search query.\"\n",
    "    \n",
    "    results = []\n",
    "    flags = 0 if case_sensitive else re.IGNORECASE\n",
    "    \n",
    "    for doc_id, doc in document_cache.items():\n",
    "        content = doc[\"content\"]\n",
    "        matches = list(re.finditer(re.escape(query), content, flags))\n",
    "        \n",
    "        if matches:\n",
    "            # Get excerpt around first match\n",
    "            first_match = matches[0]\n",
    "            start = max(0, first_match.start() - 50)\n",
    "            end = min(len(content), first_match.end() + 50)\n",
    "            excerpt = content[start:end].replace(\"\\n\", \" \")\n",
    "            \n",
    "            if start > 0:\n",
    "                excerpt = \"...\" + excerpt\n",
    "            if end < len(content):\n",
    "                excerpt = excerpt + \"...\"\n",
    "            \n",
    "            results.append({\n",
    "                \"doc_id\": doc_id,\n",
    "                \"filename\": doc[\"filename\"],\n",
    "                \"match_count\": len(matches),\n",
    "                \"excerpt\": excerpt\n",
    "            })\n",
    "    \n",
    "    if not results:\n",
    "        return f\"No documents found containing '{query}'.\"\n",
    "    \n",
    "    lines = [f\"Found {len(results)} document(s) matching '{query}':\", \"=\" * 50]\n",
    "    \n",
    "    for result in results:\n",
    "        lines.append(f\"\\nDocument: {result['doc_id']}\")\n",
    "        lines.append(f\"  Matches: {result['match_count']}\")\n",
    "        lines.append(f\"  Excerpt: {result['excerpt']}\")\n",
    "    \n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def get_document_stats() -> str:\n",
    "    \"\"\"Get statistics about the document collection.\n",
    "    \n",
    "    Returns:\n",
    "        Statistics including total documents, total size, and average document size.\n",
    "    \"\"\"\n",
    "    if not document_cache:\n",
    "        return \"No documents in the collection.\"\n",
    "    \n",
    "    total_docs = len(document_cache)\n",
    "    total_size = sum(doc[\"size\"] for doc in document_cache.values())\n",
    "    total_words = sum(len(doc[\"content\"].split()) for doc in document_cache.values())\n",
    "    \n",
    "    return f\"\"\"Document Collection Statistics:\n",
    "{'=' * 40}\n",
    "Total Documents: {total_docs}\n",
    "Total Size: {total_size:,} bytes\n",
    "Average Size: {total_size // total_docs:,} bytes\n",
    "Total Words: {total_words:,}\n",
    "Average Words per Document: {total_words // total_docs:,}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run()\n",
    "'''\n",
    "\n",
    "with open(\"document_assistant/server_step2.py\", \"w\") as f:\n",
    "    f.write(step2_code)\n",
    "\n",
    "print(\"Step 2 complete: Search tools added\")\n",
    "print(\"\\nNew tools:\")\n",
    "print(\"- list_documents(): List all available documents\")\n",
    "print(\"- search_documents(query): Search by content\")\n",
    "print(\"- get_document_stats(): Get collection statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add Resources\n",
    "\n",
    "Add resources to expose document contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3_code = '''\n",
    "\"\"\"Document Assistant MCP Server - Step 3: Resources\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "# Configuration\n",
    "DOCUMENTS_DIR = Path(__file__).parent / \"documents\"\n",
    "\n",
    "# Create the MCP server\n",
    "mcp = FastMCP(\n",
    "    \"Document Assistant\",\n",
    "    description=\"An MCP server for document management and analysis\"\n",
    ")\n",
    "\n",
    "# Document storage\n",
    "document_cache = {}\n",
    "\n",
    "def load_documents():\n",
    "    \"\"\"Load all documents from the documents directory.\"\"\"\n",
    "    global document_cache\n",
    "    document_cache = {}\n",
    "    \n",
    "    if not DOCUMENTS_DIR.exists():\n",
    "        return\n",
    "    \n",
    "    for filepath in DOCUMENTS_DIR.glob(\"*.md\"):\n",
    "        doc_id = filepath.stem\n",
    "        stat = filepath.stat()\n",
    "        \n",
    "        document_cache[doc_id] = {\n",
    "            \"id\": doc_id,\n",
    "            \"filename\": filepath.name,\n",
    "            \"path\": str(filepath),\n",
    "            \"content\": filepath.read_text(),\n",
    "            \"size\": stat.st_size,\n",
    "            \"modified\": datetime.fromtimestamp(stat.st_mtime).isoformat()\n",
    "        }\n",
    "\n",
    "load_documents()\n",
    "\n",
    "# ============ TOOLS ============\n",
    "\n",
    "@mcp.tool()\n",
    "def list_documents() -> str:\n",
    "    \"\"\"List all available documents with their metadata.\"\"\"\n",
    "    if not document_cache:\n",
    "        return \"No documents found.\"\n",
    "    \n",
    "    lines = [\"Available Documents:\", \"=\" * 50]\n",
    "    for doc_id, doc in sorted(document_cache.items()):\n",
    "        lines.append(f\"\\nID: {doc_id}\")\n",
    "        lines.append(f\"  Filename: {doc['filename']}\")\n",
    "        lines.append(f\"  Size: {doc['size']} bytes\")\n",
    "        lines.append(f\"  Modified: {doc['modified']}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def search_documents(query: str, case_sensitive: bool = False) -> str:\n",
    "    \"\"\"Search for documents containing the specified text.\"\"\"\n",
    "    if not query.strip():\n",
    "        return \"Error: Please provide a search query.\"\n",
    "    \n",
    "    results = []\n",
    "    flags = 0 if case_sensitive else re.IGNORECASE\n",
    "    \n",
    "    for doc_id, doc in document_cache.items():\n",
    "        content = doc[\"content\"]\n",
    "        matches = list(re.finditer(re.escape(query), content, flags))\n",
    "        \n",
    "        if matches:\n",
    "            first_match = matches[0]\n",
    "            start = max(0, first_match.start() - 50)\n",
    "            end = min(len(content), first_match.end() + 50)\n",
    "            excerpt = content[start:end].replace(\"\\n\", \" \")\n",
    "            \n",
    "            if start > 0:\n",
    "                excerpt = \"...\" + excerpt\n",
    "            if end < len(content):\n",
    "                excerpt = excerpt + \"...\"\n",
    "            \n",
    "            results.append({\n",
    "                \"doc_id\": doc_id,\n",
    "                \"filename\": doc[\"filename\"],\n",
    "                \"match_count\": len(matches),\n",
    "                \"excerpt\": excerpt\n",
    "            })\n",
    "    \n",
    "    if not results:\n",
    "        return f\"No documents found containing '{query}'.\"\n",
    "    \n",
    "    lines = [f\"Found {len(results)} document(s) matching '{query}':\", \"=\" * 50]\n",
    "    for result in results:\n",
    "        lines.append(f\"\\nDocument: {result['doc_id']}\")\n",
    "        lines.append(f\"  Matches: {result['match_count']}\")\n",
    "        lines.append(f\"  Excerpt: {result['excerpt']}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def get_document_stats() -> str:\n",
    "    \"\"\"Get statistics about the document collection.\"\"\"\n",
    "    if not document_cache:\n",
    "        return \"No documents in the collection.\"\n",
    "    \n",
    "    total_docs = len(document_cache)\n",
    "    total_size = sum(doc[\"size\"] for doc in document_cache.values())\n",
    "    total_words = sum(len(doc[\"content\"].split()) for doc in document_cache.values())\n",
    "    \n",
    "    return f\"\"\"Document Collection Statistics:\n",
    "{'=' * 40}\n",
    "Total Documents: {total_docs}\n",
    "Total Size: {total_size:,} bytes\n",
    "Average Size: {total_size // total_docs:,} bytes\n",
    "Total Words: {total_words:,}\n",
    "Average Words per Document: {total_words // total_docs:,}\n",
    "\"\"\"\n",
    "\n",
    "# ============ RESOURCES ============\n",
    "\n",
    "@mcp.resource(\"doc://{doc_id}\")\n",
    "def get_document(doc_id: str) -> str:\n",
    "    \"\"\"Get the full content of a specific document.\n",
    "    \n",
    "    Args:\n",
    "        doc_id: The document identifier (filename without extension)\n",
    "    \n",
    "    Returns:\n",
    "        The full content of the document\n",
    "    \"\"\"\n",
    "    if doc_id not in document_cache:\n",
    "        return f\"Error: Document '{doc_id}' not found.\"\n",
    "    \n",
    "    return document_cache[doc_id][\"content\"]\n",
    "\n",
    "\n",
    "@mcp.resource(\"docs://catalog\")\n",
    "def get_catalog() -> str:\n",
    "    \"\"\"Get the full document catalog as JSON.\n",
    "    \n",
    "    Returns:\n",
    "        JSON-formatted catalog with all document metadata\n",
    "    \"\"\"\n",
    "    catalog = []\n",
    "    for doc_id, doc in document_cache.items():\n",
    "        catalog.append({\n",
    "            \"id\": doc[\"id\"],\n",
    "            \"filename\": doc[\"filename\"],\n",
    "            \"size\": doc[\"size\"],\n",
    "            \"modified\": doc[\"modified\"],\n",
    "            \"word_count\": len(doc[\"content\"].split())\n",
    "        })\n",
    "    \n",
    "    return json.dumps(catalog, indent=2)\n",
    "\n",
    "\n",
    "@mcp.resource(\"doc://{doc_id}/metadata\")\n",
    "def get_document_metadata(doc_id: str) -> str:\n",
    "    \"\"\"Get metadata for a specific document.\n",
    "    \n",
    "    Args:\n",
    "        doc_id: The document identifier\n",
    "    \n",
    "    Returns:\n",
    "        JSON-formatted metadata for the document\n",
    "    \"\"\"\n",
    "    if doc_id not in document_cache:\n",
    "        return json.dumps({\"error\": f\"Document '{doc_id}' not found.\"})\n",
    "    \n",
    "    doc = document_cache[doc_id]\n",
    "    metadata = {\n",
    "        \"id\": doc[\"id\"],\n",
    "        \"filename\": doc[\"filename\"],\n",
    "        \"size\": doc[\"size\"],\n",
    "        \"modified\": doc[\"modified\"],\n",
    "        \"word_count\": len(doc[\"content\"].split()),\n",
    "        \"line_count\": doc[\"content\"].count(\"\\n\") + 1\n",
    "    }\n",
    "    \n",
    "    return json.dumps(metadata, indent=2)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run()\n",
    "'''\n",
    "\n",
    "with open(\"document_assistant/server_step3.py\", \"w\") as f:\n",
    "    f.write(step3_code)\n",
    "\n",
    "print(\"Step 3 complete: Resources added\")\n",
    "print(\"\\nNew resources:\")\n",
    "print(\"- doc://{doc_id} - Full document content\")\n",
    "print(\"- docs://catalog - Document catalog (JSON)\")\n",
    "print(\"- doc://{doc_id}/metadata - Document metadata (JSON)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Add Prompts\n",
    "\n",
    "Add prompts for common document analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step4_code = '''\n",
    "\"\"\"Document Assistant MCP Server - Step 4: Prompts (Complete Server)\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "# Configuration\n",
    "DOCUMENTS_DIR = Path(__file__).parent / \"documents\"\n",
    "\n",
    "# Create the MCP server\n",
    "mcp = FastMCP(\n",
    "    \"Document Assistant\",\n",
    "    description=\"An MCP server for document management and analysis\"\n",
    ")\n",
    "\n",
    "# Document storage\n",
    "document_cache = {}\n",
    "\n",
    "def load_documents():\n",
    "    \"\"\"Load all documents from the documents directory.\"\"\"\n",
    "    global document_cache\n",
    "    document_cache = {}\n",
    "    \n",
    "    if not DOCUMENTS_DIR.exists():\n",
    "        return\n",
    "    \n",
    "    for filepath in DOCUMENTS_DIR.glob(\"*.md\"):\n",
    "        doc_id = filepath.stem\n",
    "        stat = filepath.stat()\n",
    "        \n",
    "        document_cache[doc_id] = {\n",
    "            \"id\": doc_id,\n",
    "            \"filename\": filepath.name,\n",
    "            \"path\": str(filepath),\n",
    "            \"content\": filepath.read_text(),\n",
    "            \"size\": stat.st_size,\n",
    "            \"modified\": datetime.fromtimestamp(stat.st_mtime).isoformat()\n",
    "        }\n",
    "\n",
    "load_documents()\n",
    "\n",
    "# ============ TOOLS ============\n",
    "\n",
    "@mcp.tool()\n",
    "def list_documents() -> str:\n",
    "    \"\"\"List all available documents with their metadata.\"\"\"\n",
    "    if not document_cache:\n",
    "        return \"No documents found.\"\n",
    "    \n",
    "    lines = [\"Available Documents:\", \"=\" * 50]\n",
    "    for doc_id, doc in sorted(document_cache.items()):\n",
    "        lines.append(f\"\\nID: {doc_id}\")\n",
    "        lines.append(f\"  Filename: {doc['filename']}\")\n",
    "        lines.append(f\"  Size: {doc['size']} bytes\")\n",
    "        lines.append(f\"  Modified: {doc['modified']}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def search_documents(query: str, case_sensitive: bool = False) -> str:\n",
    "    \"\"\"Search for documents containing the specified text.\"\"\"\n",
    "    if not query.strip():\n",
    "        return \"Error: Please provide a search query.\"\n",
    "    \n",
    "    results = []\n",
    "    flags = 0 if case_sensitive else re.IGNORECASE\n",
    "    \n",
    "    for doc_id, doc in document_cache.items():\n",
    "        content = doc[\"content\"]\n",
    "        matches = list(re.finditer(re.escape(query), content, flags))\n",
    "        \n",
    "        if matches:\n",
    "            first_match = matches[0]\n",
    "            start = max(0, first_match.start() - 50)\n",
    "            end = min(len(content), first_match.end() + 50)\n",
    "            excerpt = content[start:end].replace(\"\\n\", \" \")\n",
    "            \n",
    "            if start > 0:\n",
    "                excerpt = \"...\" + excerpt\n",
    "            if end < len(content):\n",
    "                excerpt = excerpt + \"...\"\n",
    "            \n",
    "            results.append({\n",
    "                \"doc_id\": doc_id,\n",
    "                \"filename\": doc[\"filename\"],\n",
    "                \"match_count\": len(matches),\n",
    "                \"excerpt\": excerpt\n",
    "            })\n",
    "    \n",
    "    if not results:\n",
    "        return f\"No documents found containing '{query}'.\"\n",
    "    \n",
    "    lines = [f\"Found {len(results)} document(s) matching '{query}':\", \"=\" * 50]\n",
    "    for result in results:\n",
    "        lines.append(f\"\\nDocument: {result['doc_id']}\")\n",
    "        lines.append(f\"  Matches: {result['match_count']}\")\n",
    "        lines.append(f\"  Excerpt: {result['excerpt']}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def get_document_stats() -> str:\n",
    "    \"\"\"Get statistics about the document collection.\"\"\"\n",
    "    if not document_cache:\n",
    "        return \"No documents in the collection.\"\n",
    "    \n",
    "    total_docs = len(document_cache)\n",
    "    total_size = sum(doc[\"size\"] for doc in document_cache.values())\n",
    "    total_words = sum(len(doc[\"content\"].split()) for doc in document_cache.values())\n",
    "    \n",
    "    return f\"\"\"Document Collection Statistics:\n",
    "{'=' * 40}\n",
    "Total Documents: {total_docs}\n",
    "Total Size: {total_size:,} bytes\n",
    "Average Size: {total_size // total_docs:,} bytes\n",
    "Total Words: {total_words:,}\n",
    "Average Words per Document: {total_words // total_docs:,}\n",
    "\"\"\"\n",
    "\n",
    "# ============ RESOURCES ============\n",
    "\n",
    "@mcp.resource(\"doc://{doc_id}\")\n",
    "def get_document(doc_id: str) -> str:\n",
    "    \"\"\"Get the full content of a specific document.\"\"\"\n",
    "    if doc_id not in document_cache:\n",
    "        return f\"Error: Document '{doc_id}' not found.\"\n",
    "    return document_cache[doc_id][\"content\"]\n",
    "\n",
    "\n",
    "@mcp.resource(\"docs://catalog\")\n",
    "def get_catalog() -> str:\n",
    "    \"\"\"Get the full document catalog as JSON.\"\"\"\n",
    "    catalog = []\n",
    "    for doc_id, doc in document_cache.items():\n",
    "        catalog.append({\n",
    "            \"id\": doc[\"id\"],\n",
    "            \"filename\": doc[\"filename\"],\n",
    "            \"size\": doc[\"size\"],\n",
    "            \"modified\": doc[\"modified\"],\n",
    "            \"word_count\": len(doc[\"content\"].split())\n",
    "        })\n",
    "    return json.dumps(catalog, indent=2)\n",
    "\n",
    "\n",
    "@mcp.resource(\"doc://{doc_id}/metadata\")\n",
    "def get_document_metadata(doc_id: str) -> str:\n",
    "    \"\"\"Get metadata for a specific document.\"\"\"\n",
    "    if doc_id not in document_cache:\n",
    "        return json.dumps({\"error\": f\"Document '{doc_id}' not found.\"})\n",
    "    \n",
    "    doc = document_cache[doc_id]\n",
    "    metadata = {\n",
    "        \"id\": doc[\"id\"],\n",
    "        \"filename\": doc[\"filename\"],\n",
    "        \"size\": doc[\"size\"],\n",
    "        \"modified\": doc[\"modified\"],\n",
    "        \"word_count\": len(doc[\"content\"].split()),\n",
    "        \"line_count\": doc[\"content\"].count(\"\\n\") + 1\n",
    "    }\n",
    "    return json.dumps(metadata, indent=2)\n",
    "\n",
    "# ============ PROMPTS ============\n",
    "\n",
    "@mcp.prompt()\n",
    "def summarize(doc_id: str) -> str:\n",
    "    \"\"\"Create a prompt to summarize a document.\n",
    "    \n",
    "    Args:\n",
    "        doc_id: The document to summarize\n",
    "    \"\"\"\n",
    "    if doc_id not in document_cache:\n",
    "        return f\"Error: Document '{doc_id}' not found.\"\n",
    "    \n",
    "    doc = document_cache[doc_id]\n",
    "    return f\"\"\"Please summarize the following document:\n",
    "\n",
    "Document: {doc['filename']}\n",
    "---\n",
    "{doc['content']}\n",
    "---\n",
    "\n",
    "Provide:\n",
    "1. A brief summary (2-3 sentences)\n",
    "2. Key points (bullet list)\n",
    "3. Any action items or next steps mentioned\"\"\"\n",
    "\n",
    "\n",
    "@mcp.prompt()\n",
    "def compare(doc_id_1: str, doc_id_2: str) -> str:\n",
    "    \"\"\"Create a prompt to compare two documents.\n",
    "    \n",
    "    Args:\n",
    "        doc_id_1: The first document to compare\n",
    "        doc_id_2: The second document to compare\n",
    "    \"\"\"\n",
    "    if doc_id_1 not in document_cache:\n",
    "        return f\"Error: Document '{doc_id_1}' not found.\"\n",
    "    if doc_id_2 not in document_cache:\n",
    "        return f\"Error: Document '{doc_id_2}' not found.\"\n",
    "    \n",
    "    doc1 = document_cache[doc_id_1]\n",
    "    doc2 = document_cache[doc_id_2]\n",
    "    \n",
    "    return f\"\"\"Please compare the following two documents:\n",
    "\n",
    "=== Document 1: {doc1['filename']} ===\n",
    "{doc1['content']}\n",
    "\n",
    "=== Document 2: {doc2['filename']} ===\n",
    "{doc2['content']}\n",
    "\n",
    "Provide:\n",
    "1. Main similarities between the documents\n",
    "2. Key differences\n",
    "3. How they might relate to each other\n",
    "4. Any contradictions or inconsistencies\"\"\"\n",
    "\n",
    "\n",
    "@mcp.prompt()\n",
    "def extract_insights(doc_id: str, focus_area: str = \"general\") -> str:\n",
    "    \"\"\"Create a prompt to extract insights from a document.\n",
    "    \n",
    "    Args:\n",
    "        doc_id: The document to analyze\n",
    "        focus_area: The area to focus on (e.g., 'technical', 'business', 'security', 'general')\n",
    "    \"\"\"\n",
    "    if doc_id not in document_cache:\n",
    "        return f\"Error: Document '{doc_id}' not found.\"\n",
    "    \n",
    "    doc = document_cache[doc_id]\n",
    "    \n",
    "    focus_instructions = {\n",
    "        \"general\": \"Extract any important insights, patterns, or notable information.\",\n",
    "        \"technical\": \"Focus on technical details, architecture decisions, and implementation specifics.\",\n",
    "        \"business\": \"Focus on business impact, ROI, timelines, and strategic implications.\",\n",
    "        \"security\": \"Focus on security considerations, risks, compliance requirements, and vulnerabilities.\"\n",
    "    }\n",
    "    \n",
    "    instruction = focus_instructions.get(focus_area, focus_instructions[\"general\"])\n",
    "    \n",
    "    return f\"\"\"Please analyze the following document and extract key insights:\n",
    "\n",
    "Document: {doc['filename']}\n",
    "Focus Area: {focus_area}\n",
    "---\n",
    "{doc['content']}\n",
    "---\n",
    "\n",
    "{instruction}\n",
    "\n",
    "Format your response as:\n",
    "1. Key Insights (numbered list)\n",
    "2. Recommendations based on the document\n",
    "3. Questions that should be addressed\n",
    "4. Related topics to explore\"\"\"\n",
    "\n",
    "\n",
    "@mcp.prompt()\n",
    "def generate_questions(doc_id: str) -> str:\n",
    "    \"\"\"Create a prompt to generate questions about a document.\n",
    "    \n",
    "    Args:\n",
    "        doc_id: The document to generate questions for\n",
    "    \"\"\"\n",
    "    if doc_id not in document_cache:\n",
    "        return f\"Error: Document '{doc_id}' not found.\"\n",
    "    \n",
    "    doc = document_cache[doc_id]\n",
    "    \n",
    "    return f\"\"\"Based on the following document, generate thoughtful questions that would help clarify or expand on the content:\n",
    "\n",
    "Document: {doc['filename']}\n",
    "---\n",
    "{doc['content']}\n",
    "---\n",
    "\n",
    "Generate:\n",
    "1. 5 clarifying questions (things that are unclear or need more detail)\n",
    "2. 5 follow-up questions (things to explore further)\n",
    "3. 3 devil's advocate questions (potential issues or challenges)\"\"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run()\n",
    "'''\n",
    "\n",
    "# Save as the final server\n",
    "with open(\"document_assistant/server.py\", \"w\") as f:\n",
    "    f.write(step4_code)\n",
    "\n",
    "print(\"Step 4 complete: Prompts added - Server is complete!\")\n",
    "print(\"\\nNew prompts:\")\n",
    "print(\"- summarize(doc_id) - Summarize a document\")\n",
    "print(\"- compare(doc_id_1, doc_id_2) - Compare two documents\")\n",
    "print(\"- extract_insights(doc_id, focus_area) - Extract insights with focus\")\n",
    "print(\"- generate_questions(doc_id) - Generate questions about a document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Testing Your Server\n",
    "\n",
    "Let's test the complete Document Assistant server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with MCP Inspector\n",
    "\n",
    "Run in terminal:\n",
    "```bash\n",
    "cd document_assistant\n",
    "mcp dev server.py\n",
    "```\n",
    "\n",
    "Then test:\n",
    "1. **Tools**: Call `list_documents()`, `search_documents(\"AI\")`, `get_document_stats()`\n",
    "2. **Resources**: Access `doc://project_proposal`, `docs://catalog`\n",
    "3. **Prompts**: Use `summarize` with `doc_id=\"project_proposal\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test checklist\n",
    "\n",
    "test_results = {\n",
    "    \"tools\": {\n",
    "        \"list_documents\": {\n",
    "            \"tested\": False,\n",
    "            \"passed\": False,\n",
    "            \"notes\": \"\"\n",
    "        },\n",
    "        \"search_documents\": {\n",
    "            \"tested\": False,\n",
    "            \"passed\": False,\n",
    "            \"query_used\": \"\",\n",
    "            \"results_count\": 0,\n",
    "            \"notes\": \"\"\n",
    "        },\n",
    "        \"get_document_stats\": {\n",
    "            \"tested\": False,\n",
    "            \"passed\": False,\n",
    "            \"notes\": \"\"\n",
    "        }\n",
    "    },\n",
    "    \"resources\": {\n",
    "        \"doc://project_proposal\": {\n",
    "            \"tested\": False,\n",
    "            \"passed\": False,\n",
    "            \"notes\": \"\"\n",
    "        },\n",
    "        \"docs://catalog\": {\n",
    "            \"tested\": False,\n",
    "            \"passed\": False,\n",
    "            \"notes\": \"\"\n",
    "        },\n",
    "        \"doc://project_proposal/metadata\": {\n",
    "            \"tested\": False,\n",
    "            \"passed\": False,\n",
    "            \"notes\": \"\"\n",
    "        }\n",
    "    },\n",
    "    \"prompts\": {\n",
    "        \"summarize\": {\n",
    "            \"tested\": False,\n",
    "            \"passed\": False,\n",
    "            \"notes\": \"\"\n",
    "        },\n",
    "        \"compare\": {\n",
    "            \"tested\": False,\n",
    "            \"passed\": False,\n",
    "            \"notes\": \"\"\n",
    "        },\n",
    "        \"extract_insights\": {\n",
    "            \"tested\": False,\n",
    "            \"passed\": False,\n",
    "            \"notes\": \"\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Test your server with MCP Inspector and fill in the results above!\")\n",
    "print(\"\\nRun: cd document_assistant && mcp dev server.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: VS Code Integration\n",
    "\n",
    "Connect your Document Assistant to VS Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the full path to the server\n",
    "server_path = os.path.abspath(\"document_assistant/server.py\")\n",
    "\n",
    "print(\"Add this to your VS Code settings.json:\")\n",
    "print()\n",
    "print('''{\n",
    "  \"github.copilot.chat.experimental.mcp.servers\": {\n",
    "    \"document-assistant\": {\n",
    "      \"command\": \"python\",\n",
    "      \"args\": [\"''' + server_path + '''\"]\n",
    "    }\n",
    "  }\n",
    "}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing in VS Code\n",
    "\n",
    "After configuring, try these prompts in GitHub Copilot Chat:\n",
    "\n",
    "1. \"List all my documents\"\n",
    "2. \"Search for documents about AI\"\n",
    "3. \"Summarize the project proposal\"\n",
    "4. \"Compare the project proposal with the technical spec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document your VS Code testing\n",
    "\n",
    "vscode_tests = {\n",
    "    \"server_connected\": False,\n",
    "    \"test_prompts\": [\n",
    "        {\n",
    "            \"prompt\": \"List all my documents\",\n",
    "            \"tool_called\": \"\",\n",
    "            \"result_quality\": \"\"  # Good/Okay/Poor\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"Search for documents about AI\",\n",
    "            \"tool_called\": \"\",\n",
    "            \"result_quality\": \"\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"Summarize the project proposal\",\n",
    "            \"tool_called\": \"\",\n",
    "            \"result_quality\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"overall_experience\": \"\"\n",
    "}\n",
    "\n",
    "print(\"Document your VS Code integration experience above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Extension Challenges\n",
    "\n",
    "Extend your Document Assistant with additional features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Add Document Creation\n",
    "\n",
    "Add a tool to create new documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a create_document tool\n",
    "\n",
    "create_document_code = '''\n",
    "@mcp.tool()\n",
    "def create_document(doc_id: str, content: str, overwrite: bool = False) -> str:\n",
    "    \"\"\"Create a new document in the collection.\n",
    "    \n",
    "    Args:\n",
    "        doc_id: The identifier for the new document (will be used as filename)\n",
    "        content: The content of the document\n",
    "        overwrite: Whether to overwrite if document exists (default: False)\n",
    "    \n",
    "    Returns:\n",
    "        Success message or error\n",
    "    \"\"\"\n",
    "    # TODO: Implement this tool\n",
    "    # 1. Check if document already exists (unless overwrite=True)\n",
    "    # 2. Write the file to DOCUMENTS_DIR\n",
    "    # 3. Reload the document cache\n",
    "    # 4. Return success message\n",
    "    pass\n",
    "'''\n",
    "\n",
    "print(\"Challenge 1: Implement the create_document tool\")\n",
    "print(create_document_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Add Tag Support\n",
    "\n",
    "Add tagging capabilities to documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement tag support\n",
    "\n",
    "tag_support_code = '''\n",
    "# Store tags in a separate JSON file\n",
    "TAGS_FILE = DOCUMENTS_DIR / \"tags.json\"\n",
    "\n",
    "def load_tags() -> dict:\n",
    "    \"\"\"Load tags from the tags file.\"\"\"\n",
    "    if TAGS_FILE.exists():\n",
    "        return json.loads(TAGS_FILE.read_text())\n",
    "    return {}\n",
    "\n",
    "def save_tags(tags: dict):\n",
    "    \"\"\"Save tags to the tags file.\"\"\"\n",
    "    TAGS_FILE.write_text(json.dumps(tags, indent=2))\n",
    "\n",
    "@mcp.tool()\n",
    "def add_tag(doc_id: str, tag: str) -> str:\n",
    "    \"\"\"Add a tag to a document.\n",
    "    \n",
    "    Args:\n",
    "        doc_id: The document to tag\n",
    "        tag: The tag to add\n",
    "    \"\"\"\n",
    "    # TODO: Implement this\n",
    "    pass\n",
    "\n",
    "@mcp.tool()\n",
    "def search_by_tag(tag: str) -> str:\n",
    "    \"\"\"Find all documents with a specific tag.\n",
    "    \n",
    "    Args:\n",
    "        tag: The tag to search for\n",
    "    \"\"\"\n",
    "    # TODO: Implement this\n",
    "    pass\n",
    "\n",
    "@mcp.tool()\n",
    "def list_tags() -> str:\n",
    "    \"\"\"List all tags and their document counts.\"\"\"\n",
    "    # TODO: Implement this\n",
    "    pass\n",
    "'''\n",
    "\n",
    "print(\"Challenge 2: Implement tag support\")\n",
    "print(tag_support_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Add Version History\n",
    "\n",
    "Track document versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement version history\n",
    "\n",
    "version_history_code = '''\n",
    "# Store versions in a subdirectory\n",
    "VERSIONS_DIR = DOCUMENTS_DIR / \".versions\"\n",
    "\n",
    "@mcp.tool()\n",
    "def update_document(doc_id: str, new_content: str) -> str:\n",
    "    \"\"\"Update a document, saving the previous version.\n",
    "    \n",
    "    Args:\n",
    "        doc_id: The document to update\n",
    "        new_content: The new content\n",
    "    \"\"\"\n",
    "    # TODO: Implement this\n",
    "    # 1. Save current version to VERSIONS_DIR with timestamp\n",
    "    # 2. Write new content to document\n",
    "    # 3. Reload cache\n",
    "    pass\n",
    "\n",
    "@mcp.tool()\n",
    "def list_versions(doc_id: str) -> str:\n",
    "    \"\"\"List all versions of a document.\n",
    "    \n",
    "    Args:\n",
    "        doc_id: The document to list versions for\n",
    "    \"\"\"\n",
    "    # TODO: Implement this\n",
    "    pass\n",
    "\n",
    "@mcp.resource(\"doc://{doc_id}/version/{version_id}\")\n",
    "def get_document_version(doc_id: str, version_id: str) -> str:\n",
    "    \"\"\"Get a specific version of a document.\n",
    "    \n",
    "    Args:\n",
    "        doc_id: The document\n",
    "        version_id: The version timestamp\n",
    "    \"\"\"\n",
    "    # TODO: Implement this\n",
    "    pass\n",
    "'''\n",
    "\n",
    "print(\"Challenge 3: Implement version history\")\n",
    "print(version_history_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Programmatic Access\n",
    "\n",
    "Use the MCP Client SDK to access your Document Assistant programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmatic client for Document Assistant\n",
    "\n",
    "client_code = '''\n",
    "\"\"\"Programmatic client for the Document Assistant MCP server.\"\"\"\n",
    "\n",
    "import asyncio\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "async def main():\n",
    "    server_params = StdioServerParameters(\n",
    "        command=\"python\",\n",
    "        args=[\"server.py\"]\n",
    "    )\n",
    "    \n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            # Initialize\n",
    "            await session.initialize()\n",
    "            \n",
    "            # List all documents\n",
    "            print(\"=\" * 50)\n",
    "            print(\"Listing documents...\")\n",
    "            result = await session.call_tool(\"list_documents\", {})\n",
    "            print(result.content[0].text)\n",
    "            \n",
    "            # Search for \"AI\"\n",
    "            print(\"\\n\" + \"=\" * 50)\n",
    "            print(\"Searching for 'AI'...\")\n",
    "            result = await session.call_tool(\"search_documents\", {\"query\": \"AI\"})\n",
    "            print(result.content[0].text)\n",
    "            \n",
    "            # Get document via resource\n",
    "            print(\"\\n\" + \"=\" * 50)\n",
    "            print(\"Reading project_proposal via resource...\")\n",
    "            resources = await session.list_resources()\n",
    "            for resource in resources.resources:\n",
    "                print(f\"  Available: {resource.uri}\")\n",
    "            \n",
    "            # Get collection stats\n",
    "            print(\"\\n\" + \"=\" * 50)\n",
    "            print(\"Getting statistics...\")\n",
    "            result = await session.call_tool(\"get_document_stats\", {})\n",
    "            print(result.content[0].text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n",
    "'''\n",
    "\n",
    "with open(\"document_assistant/client.py\", \"w\") as f:\n",
    "    f.write(client_code)\n",
    "\n",
    "print(\"Client code saved to document_assistant/client.py\")\n",
    "print(\"\\nRun with: cd document_assistant && python client.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Final Review\n",
    "\n",
    "Let's review what you've built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final project summary\n",
    "\n",
    "project_summary = {\n",
    "    \"server_name\": \"Document Assistant\",\n",
    "    \"components\": {\n",
    "        \"tools\": [\n",
    "            \"list_documents() - List all documents\",\n",
    "            \"search_documents(query) - Search by content\",\n",
    "            \"get_document_stats() - Collection statistics\"\n",
    "        ],\n",
    "        \"resources\": [\n",
    "            \"doc://{doc_id} - Document content\",\n",
    "            \"docs://catalog - Full catalog (JSON)\",\n",
    "            \"doc://{doc_id}/metadata - Document metadata\"\n",
    "        ],\n",
    "        \"prompts\": [\n",
    "            \"summarize(doc_id) - Summarize document\",\n",
    "            \"compare(doc_id_1, doc_id_2) - Compare documents\",\n",
    "            \"extract_insights(doc_id, focus_area) - Extract insights\",\n",
    "            \"generate_questions(doc_id) - Generate questions\"\n",
    "        ]\n",
    "    },\n",
    "    \"files_created\": [\n",
    "        \"document_assistant/server.py - Main server\",\n",
    "        \"document_assistant/client.py - Programmatic client\",\n",
    "        \"document_assistant/documents/*.md - Sample documents\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Document Assistant MCP Server\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nTools:\")\n",
    "for tool in project_summary[\"components\"][\"tools\"]:\n",
    "    print(f\"  - {tool}\")\n",
    "print(\"\\nResources:\")\n",
    "for resource in project_summary[\"components\"][\"resources\"]:\n",
    "    print(f\"  - {resource}\")\n",
    "print(\"\\nPrompts:\")\n",
    "for prompt in project_summary[\"components\"][\"prompts\"]:\n",
    "    print(f\"  - {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Summary\n",
    "\n",
    "Congratulations! You've built a complete Document Assistant MCP server that demonstrates:\n",
    "\n",
    "1. **Tools** for searching and listing documents\n",
    "2. **Resources** for accessing document contents and metadata\n",
    "3. **Prompts** for common document analysis tasks\n",
    "4. **Integration** with VS Code and programmatic access\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Tools** are for actions (search, list, stats)\n",
    "- **Resources** are for data access (read content, get metadata)\n",
    "- **Prompts** are for reusable workflows (summarize, compare, analyze)\n",
    "- Good docstrings are critical for tool discovery\n",
    "- Test with MCP Inspector before integrating\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "- Add your own document types and tools\n",
    "- Implement the extension challenges\n",
    "- Connect to real document storage (S3, database, etc.)\n",
    "- Build more complex analysis prompts\n",
    "\n",
    "### Workshop Complete!\n",
    "\n",
    "You now have the skills to build custom MCP servers for any use case. The patterns you learned apply to:\n",
    "- Database assistants\n",
    "- API integrations\n",
    "- Development tools\n",
    "- Business applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final reflection\n",
    "\n",
    "reflection = {\n",
    "    \"most_valuable_learning\": \"\",\n",
    "    \"challenges_faced\": \"\",\n",
    "    \"ideas_for_own_projects\": \"\",\n",
    "    \"questions_remaining\": \"\"\n",
    "}\n",
    "\n",
    "print(\"Reflect on your learning experience above!\")\n",
    "print(\"\\nThank you for completing the MCP Workshop!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
